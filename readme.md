# Robot Vision AI - 12 Month Learning Project

A year-long hands-on learning journey to understand AI, machine learning, computer vision, and robotics by building an autonomous voice-controlled robot from scratch.

## ğŸ¯ Project Goals

Build a robot that can:
- Respond to voice commands (start, stop, navigate, return home)
- Traverse an office floor autonomously
- Detect and avoid obstacles (furniture, walls, coffee cups)
- Use computer vision and sensors for navigation
- All while **understanding how and why it works**

## ğŸ”§ Constraints & Philosophy

**Hardware Requirements:**
- Raspberry Pi 4/5 (4GB+ RAM)
- Pi Camera or USB webcam
- Ultrasonic distance sensors (HC-SR04)
- DC motors + motor controller (L298N)
- 3D printed chassis (Prusa MK4)
- USB microphone
- Budget: ~$150-250

**Software Constraints:**
- âœ… MUST be open source
- âœ… MUST run on Raspberry Pi (no cloud dependency for core functions)
- âœ… MUST be free (no paid APIs)
- âŒ NO proprietary software
- âŒ NO mandatory internet connection
- âŒ NO expensive hardware (no Jetson, no LiDAR)

**Philosophy:**
> This is NOT about building the world's best robot.
> This IS about **understanding AI, ML, computer vision, and robotics**.
> The robot is the vehicle for learning. The knowledge gained is the destination.

## ğŸ“š Learning Progression

### Phase 1: Foundations (Months 1-2)
**Topics:** `01_fundamentals/` & `02_computer_vision/`
- Python ML basics (K-NN, decision trees)
- OpenCV fundamentals (edge detection, color tracking)
- Image processing basics
- **Deliverable:** Webcam obstacle detection running on PC

### Phase 2: Advanced Vision & Hardware (Months 3-4)
**Topics:** `03_machine_learning/` & `04_hardware/`
- Object detection (YOLO Nano)
- Raspberry Pi GPIO programming
- Motor control and sensor reading
- 3D printing robot chassis
- **Deliverable:** Assembled robot with basic motor control

### Phase 3: Navigation (Months 5-8)
**Topics:** `05_navigation/` & `06_sensor_fusion/`
- Path planning algorithms (A*, potential fields)
- Obstacle avoidance (geometry + sensors)
- Combining camera + sensor data
- Dead reckoning and localization
- **Deliverable:** Robot navigates room avoiding obstacles

### Phase 4: Integration & Voice (Months 9-12)
**Topics:** `07_voice_control/` & final integration
- Voice recognition (Vosk - offline)
- Command parsing
- System integration
- Testing and refinement
- **Deliverable:** Voice-controlled autonomous robot

## ğŸ—‚ï¸ Project Structure
```
ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ learning/              # Learning exercises by topic
â”‚   â”‚   â”œâ”€â”€ 01_fundamentals/   # ML basics, Python fundamentals
â”‚   â”‚   â”œâ”€â”€ 02_computer_vision/# OpenCV, image processing
â”‚   â”‚   â”œâ”€â”€ 03_machine_learning/# Vision ML (YOLO, classifiers)
â”‚   â”‚   â”œâ”€â”€ 04_hardware/       # Raspberry Pi, sensors, motors
â”‚   â”‚   â”œâ”€â”€ 05_navigation/     # Path planning, obstacle avoidance
â”‚   â”‚   â”œâ”€â”€ 06_sensor_fusion/  # Combining camera + sensors
â”‚   â”‚   â””â”€â”€ 07_voice_control/  # Speech recognition, commands
â”‚   â”‚
â”‚   â”œâ”€â”€ robot/                 # Production robot code
â”‚   â”‚   â”œâ”€â”€ control.py         # Motor control
â”‚   â”‚   â”œâ”€â”€ sensors.py         # Sensor reading
â”‚   â”‚   â”œâ”€â”€ vision.py          # Computer vision processing
â”‚   â”‚   â”œâ”€â”€ navigation.py      # Navigation logic
â”‚   â”‚   â””â”€â”€ voice.py           # Voice command handling
â”‚   â”‚
â”‚   â””â”€â”€ utils/                 # Shared utility functions
â”‚       â”œâ”€â”€ image_utils.py
â”‚       â”œâ”€â”€ math_utils.py
â”‚       â””â”€â”€ config.py
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for exploration
â”œâ”€â”€ configs/                   # YAML configuration files
â”œâ”€â”€ datasets/                  # Training/test data
â”œâ”€â”€ models/                    # Trained ML models
â”œâ”€â”€ hardware/                  # 3D prints, schematics
â”œâ”€â”€ tests/                     # Unit tests
â”œâ”€â”€ pyproject.toml            # Project dependencies
â””â”€â”€ README.md                 # This file
```

## ğŸ› ï¸ Technology Stack

**Core:**
- Python 3.9+
- OpenCV (cv2) - Computer vision
- NumPy/SciPy - Math operations
- Raspberry Pi OS (Debian-based)

**Machine Learning:**
- scikit-learn - Classical ML
- YOLOv8 Nano - Object detection (6 MB)
- TensorFlow Lite - Edge AI inference

**Voice:**
- Vosk (50 MB model) - Offline speech-to-text
- PyAudio - Microphone access

**Hardware:**
- RPi.GPIO / gpiozero - GPIO control
- OpenCV - Camera interface

**Development:**
- VS Code
- Git/GitHub
- Jupyter Notebooks

## ğŸš€ Getting Started

### Setup Development Environment
```bash
# Clone repository
git clone https://github.com/MichaelHBaker/ai.git
cd ai

# Create virtual environment
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate

# Activate (Linux/Mac)
source .venv/bin/activate

# Install in editable mode
pip install -e .
```

### Run Learning Exercises
```bash
# Simple ML classifier
python src/learning/01_fundamentals/simple_ml.py

# OpenCV hello world
python src/learning/02_computer_vision/hello_opencv.py
```

## ğŸ“‹ Success Criteria

**Final Robot Demo:**
1. Place robot at Point A in office
2. Say "Start"
3. Robot autonomously navigates to Point B
4. Avoids all obstacles (furniture, walls, coffee cups)
5. Say "Stop" - robot halts immediately
6. Say "Return home" - robot returns to Point A
7. **Most importantly: I understand how and why it works!**

## ğŸ“ Learning vs Production Code

**`src/learning/`** - Educational exercises
- Experimental code
- Learning algorithms from scratch
- Understanding fundamentals
- Lots of comments and explanations

**`src/robot/`** - Production code
- Code that actually runs on the robot
- Optimized and tested
- Minimal dependencies
- Production-ready

## ğŸ“– Key Concepts

**Non-Learning Algorithms:**
- Edge detection (Canny, Sobel)
- Path planning (A*, Dijkstra)
- Obstacle avoidance (potential fields)
- PID control

**Learning Algorithms (ML):**
- K-Nearest Neighbors
- Decision Trees
- Neural Networks (YOLO for object detection)
- Reinforcement Learning (future exploration)

## ğŸ¤ Contributing

This is a personal learning project, but feedback and suggestions are welcome! Feel free to:
- Open issues for questions or discussions
- Suggest improvements to learning approaches
- Share similar projects or resources

## ğŸ“ License

MIT License - Feel free to use this for your own learning!

## ğŸ™ Acknowledgments

- OpenCV community for amazing computer vision tools
- Raspberry Pi Foundation for accessible hardware
- Open source ML community
- Claude (Anthropic) for learning guidance and pair programming

---

**Current Progress:** âœ… Month 1 - Foundations
**Last Updated:** 2025-01-11
**Next Milestone:** Complete computer vision fundamentals